{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "    raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-11-00f1559135a2>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-00f1559135a2>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    PATH_TO_MODEL = 'pack_detector/models/faster_rcnn_nas/research/object_detection/frozen_inference_graph.pb'.pb'\u001b[0m\n\u001b[0m                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# paths to main folders: with frozen graph, with classes labels, \n",
    "# with all shelves images and with data\n",
    "PATH_TO_MODEL = 'pack_detector/models/faster_rcnn_nas/research/object_detection/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = 'pack_detector/data/pack.pbtxt'\n",
    "PATH_TO_IMAGES = 'images/'\n",
    "PATH_TO_DATA = 'data/'\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>fileName</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>xmax</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>is_train</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb8</td>\n",
       "      <td>BB-8_3</td>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>443</td>\n",
       "      <td>23</td>\n",
       "      <td>480</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb8</td>\n",
       "      <td>BB-8_5</td>\n",
       "      <td>332</td>\n",
       "      <td>800</td>\n",
       "      <td>442</td>\n",
       "      <td>332</td>\n",
       "      <td>332</td>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bb8</td>\n",
       "      <td>BB-8_8</td>\n",
       "      <td>332</td>\n",
       "      <td>800</td>\n",
       "      <td>541</td>\n",
       "      <td>116</td>\n",
       "      <td>332</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb8</td>\n",
       "      <td>BB-8_10</td>\n",
       "      <td>683</td>\n",
       "      <td>1024</td>\n",
       "      <td>696</td>\n",
       "      <td>354</td>\n",
       "      <td>622</td>\n",
       "      <td>168</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bb8</td>\n",
       "      <td>BB-8_11</td>\n",
       "      <td>402</td>\n",
       "      <td>634</td>\n",
       "      <td>257</td>\n",
       "      <td>144</td>\n",
       "      <td>385</td>\n",
       "      <td>233</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class fileName  height  width  xmax  xmin  ymax  ymin  is_train category\n",
       "2    bb8   BB-8_3     480    480   443    23   480   155     False        1\n",
       "4    bb8   BB-8_5     332    800   442   332   332   208     False        1\n",
       "7    bb8   BB-8_8     332    800   541   116   332    43     False        1\n",
       "9    bb8  BB-8_10     683   1024   696   354   622   168     False        1\n",
       "10   bb8  BB-8_11     402    634   257   144   385   233     False        1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droids = pd.read_pickle(f'{PATH_TO_DATA}droids_df.pkl')\n",
    "droids = droids[~droids.is_train]\n",
    "droids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "model/frozen_inference_graph.pb; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9ae1d41e5dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mod_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mserialized_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mod_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mod_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/1cloud/1cloud/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/1cloud/1cloud/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m     83\u001b[0m       self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 84\u001b[0;31m           compat.as_bytes(self.__name), 1024 * 512)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: model/frozen_inference_graph.pb; No such file or directory"
     ]
    }
   ],
   "source": [
    "# load frozen graph\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load categories (we have only 1 category pack)\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, \n",
    "                                                            max_num_classes=NUM_CLASSES, \n",
    "                                                            use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, image_tensor, sess, tensor_dict):\n",
    "    # Run inference\n",
    "    expanded_dims = np.expand_dims(image, 0)\n",
    "    feed_dict={image_tensor: expanded_dims}\n",
    "    print('feed_dict:', len(expanded_dims))\n",
    "    output_dict = sess.run(tensor_dict, feed_dict)\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_image_part(image_tensor, sess, tensor_dict, \n",
    "                                 image, cutoff, ax0, ay0, ax1, ay1):\n",
    "    boxes = []\n",
    "    im = image[ay0:ay1, ax0:ax1]\n",
    "    h, w, c = im.shape\n",
    "    output_dict = run_inference_for_single_image(im, image_tensor, sess, tensor_dict)\n",
    "    for i in range(100):\n",
    "        if output_dict['detection_scores'][i] < cutoff:\n",
    "            break\n",
    "        y0, x0, y1, x1, score = *output_dict['detection_boxes'][i], \\\n",
    "                                output_dict['detection_scores'][i]\n",
    "        x0, y0, x1, y1, score = int(x0*w), int(y0*h), \\\n",
    "                                int(x1*w), int(y1*h), \\\n",
    "                                int(score * 100)\n",
    "        boxes.append((x0+ax0, y0+ay0, x1+ax0, y1+ay0, score))\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_image_part_pcnt(image_tensor, sess, tensor_dict, \n",
    "                                 image, cutoff, p_ax0, p_ay0, p_ax1, p_ay1):\n",
    "    h, w, c = image.shape\n",
    "    max_x, max_y = w-1, h-1\n",
    "    return run_inference_for_image_part(\n",
    "                                image_tensor, sess, tensor_dict, \n",
    "                                image, cutoff, \n",
    "                                int(p_ax0*max_x), int(p_ay0*max_y), \n",
    "                                int(p_ax1*max_x), int(p_ay1*max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_boxes(image, boxes, p_x0=0, p_y0=0, p_x1=1, p_y1=1):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    for x0, y0, x1, y1, score in boxes:\n",
    "        image = cv2.rectangle(image, (x0, y0), (x1, y1), (0,255,0), 5)\n",
    "    if p_x0 != 0 or p_y0 !=0 or p_x1 != 1 or p_y1 != 1:\n",
    "        h, w, c = image.shape\n",
    "        max_x, max_y = w-1, h-1\n",
    "        image = cv2.rectangle(image, \n",
    "                              (int(p_x0*max_x), int(p_y0*max_y)), \n",
    "                              (int(p_x1*max_x), int(p_y1*max_y)), (0,0,255), 5)\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_graph():\n",
    "    ops = tf.get_default_graph().get_operations()\n",
    "    all_tensor_names = {output.name\n",
    "                        for op in ops\n",
    "                        for output in op.outputs}\n",
    "    tensor_dict = {}\n",
    "    for key in ['num_detections', 'detection_boxes',\n",
    "                'detection_scores', 'detection_classes',\n",
    "                'detection_masks']:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "            tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
    "    image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "    return image_tensor, tensor_dict\n",
    "\n",
    "# starting function for inference\n",
    "def do_inference_and_display(file, cutoff, p_x0=0, p_y0=0, p_x1=1, p_y1=1):\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            image_tensor, tensor_dict = initialize_graph()\n",
    "            image = cv2.imread(f'{PATH_TO_IMAGES}{file}.jpg')\n",
    "            print(image.shape)\n",
    "            h, w, c = image.shape\n",
    "            boxes = run_inference_for_image_part_pcnt(image_tensor, \n",
    "                                                      sess, tensor_dict, \n",
    "                                                      image, \n",
    "                                                      cutoff, \n",
    "                                                      p_x0, p_y0, p_x1, p_y1)\n",
    "            display_image_with_boxes(image, boxes, p_x0, p_y0, p_x1, p_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to save time let's start with really hard image\n",
    "do_inference_and_display('BB-8_2', 0.5, 0.2, 0.2, 0.7, 1)\n",
    "# it works not bad, but not with 100% quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
