import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

base_dir = 'Datasets'
train_dir = 'Datasets/train'
validation_dir = 'Datasets/test'

train_pumba_dir = 'Datasets/train/pumba'
train_surik_dir = 'Datasets/train/surik'
validation_pumba_dir = 'Datasets/test/pumba'
validation_surik_dir = 'Datasets/test/surik'

pumba_tr = len(os.listdir(train_pumba_dir))
surik_tr = len(os.listdir(train_surik_dir))

pumba_validation = len(os.listdir(validation_pumba_dir))
surik_validation = len(os.listdir(validation_surik_dir))

total_validation = pumba_validation + surik_validation
total_train = pumba_tr + surik_tr

print('Кабанов в тестовом наборе данных: ', pumba_tr)
print('Сурикатов в тестовом наборе данных: ', surik_tr)
print('Кабанов в валидационном наборе данных: ', pumba_validation)
print('Сурикатов в валидационном наборе данных: ', surik_validation)

print('Животных в тестовом наборе данных: ', total_train)
print('Животных в валидационном наборе данных: ', total_validation)

BATCH_SIZE = 32 # количество тренировочных изображений для обработки перед обновлением параметров модели
IMG_SHAPE = 80 # размерность 80x80 к которой будет преведено входное изображение

train_image_generator = ImageDataGenerator(rescale=1./255)
validation_image_generator = ImageDataGenerator(rescale=1./255)

train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                          directory=train_dir,
                                                          shuffle=True,
                                                          target_size=(IMG_SHAPE,IMG_SHAPE),
                                                          class_mode="binary")
train_data_gen.class_indices

validation_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                              directory=validation_dir,
                                                              shuffle=False,
                                                              target_size=(IMG_SHAPE,IMG_SHAPE),
                                                              class_mode="binary")
validation_data_gen.class_indices

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SHAPE, IMG_SHAPE, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
              
model.summary()

EPOCHS = 100
history = model.fit(
    train_data_gen,
    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),
    epochs=EPOCHS,
    validation_data=validation_data_gen,
    validation_steps=int(np.ceil(total_validation / float(BATCH_SIZE)))
)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

print('Точность на обучении: ', acc[-1])
print('Точность на валидации: ', val_acc[-1])
print('Потери на обучении: ', loss[-1])
print('Потери на валидации: ', val_loss[-1])
